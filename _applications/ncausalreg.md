---
title: "Neural Causal Regularization"
collection: applications
permalink: /applications/ncausalreg
---

# Neural Causal Regularization

Neural Causal Regularization (NCR) is a framework that extends causal invariance principles to deep neural networks. Our approach trains on data from multiple environments and penalizes the variance of prediction risks across these environments, encouraging the model to learn features that lead to stable performance.

## Key Features

- Extends causal invariance to deep learning models
- Improves out-of-distribution generalization
- Maintains competitive performance on in-distribution data
- Provides theoretical guarantees under certain conditions

## Resources

- [Project Website](https://franciscorichter.github.io/ncausalreg/)
- [GitHub Repository](https://github.com/franciscorichter/ncausalreg)
- [Paper](https://arxiv.org/abs/xxxx.xxxxx)

## Applications

Neural Causal Regularization has been successfully applied to various domains, including:

- Computer vision
- Natural language processing
- Healthcare
- Climate science

## Citation

If you use NCR in your research, please cite:

```
@article{richter2023neural,
  title={Neural Causal Regularization: Extending Causal Invariance to Deep Models},
  author={Richter, Francisco M. and Pires, Bernardo Ávila and Müller, Klaus-Robert and Kloft, Marius},
  journal={Journal of Machine Learning Research},
  year={2023}
}
```
